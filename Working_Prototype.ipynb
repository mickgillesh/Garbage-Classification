{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment of Classification Model and Active Contouring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Object Classification and Localisation using Active Contouring. Interface created Using Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "#!pip install gradio\n",
    "#!pip install notebook-as-pdf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from skimage import io\n",
    "from skimage import data\n",
    "from skimage.filters import gaussian\n",
    "from skimage.segmentation import active_contour\n",
    "import os, random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gradio as gr\n",
    "\n",
    "import tensorflow.keras as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.layers import Flatten , Dense, Dropout , MaxPool2D\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Function which will return class of garbage and localised image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_and_localise(image):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    #Localise the image using Active Contouring\n",
    "    image_resize = resize(image, (224,224), anti_aliasing=True)\n",
    "    image_gray = rgb2gray(image_resize)\n",
    "    # Applying Gaussian Filter to remove noise\n",
    "    image_gray_smoothed = gaussian(image_gray, 4)\n",
    "    image_gray_smoothed = image_gray\n",
    "    # Localising the circle's center at 112, 112 with radius 112\n",
    "    x1 = 112 + 112*np.cos(np.linspace(0, 2*np.pi, 500))\n",
    "    x2 = 112 + 112*np.sin(np.linspace(0, 2*np.pi, 500))\n",
    "    # Generating a circle based on x1, x2\n",
    "    snake = np.array([x1, x2]).T\n",
    "    object_snake = active_contour(image_gray_smoothed,snake, \n",
    "                                  alpha=0.5, beta=0.1, w_line=0, \n",
    "                                  w_edge=1, gamma=0.01, max_px_move=1.0, \n",
    "                                  max_iterations=2500, convergence=0.1, \n",
    "                                  boundary_condition='periodic', coordinates='rc')\n",
    "                                  \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # Adding subplots to display the markers\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    # Plotting sample image\n",
    "    ax.imshow(image_resize)\n",
    "    \n",
    "    # Plotting the face boundary marker\n",
    "    ax.plot(object_snake[:, 1],\n",
    "            object_snake[:, 0],\n",
    "            '-r', lw=5)\n",
    "    \n",
    "\n",
    "\n",
    "    #pass image through CNN to get class\n",
    "    image2 = tf.image.resize(image,size = (224,224))\n",
    "    image_reshape = np.expand_dims(image2, axis=0)\n",
    "    image_preprocessed = tf.keras.applications.resnet50.preprocess_input(image_reshape.copy())\n",
    "  \n",
    "    model = load_model(\"bestmodel.h5\")\n",
    "    classification = model.predict(image_preprocessed)\n",
    "    classes = ['battery','biological','brown-glass','cardboard','clothes','green-glass','metal','paper','plastic','shoes','trash','white-glass']\n",
    "    \n",
    "    classification_label = classes[np.argmax(classification)]\n",
    "\n",
    "\n",
    "    return classification_label, plt.gcf()\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launching the user interface using Gradio Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"http://127.0.0.1:7860/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x168d2e0fc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<fastapi.applications.FastAPI at 0x168cb42e6a0>,\n",
       " 'http://127.0.0.1:7860/',\n",
       " None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = \"Garbage_Classification\"\n",
    "description = \"Demo for Garbage Classification and Localisation. Upload your own image and click \" \\\n",
    "              \"\\\"Submit\\\" \"\n",
    "io = gr.Interface(classify_and_localise, inputs=gr.inputs.Image(),\n",
    "                  outputs = [\"text\",\"plot\"],\n",
    "                  title=title, description=description,\n",
    "                  allow_flagging=False, allow_screenshot=False)\n",
    "io.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export Jupyter Notebook to PDF for the Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n",
      "[NbConvertApp] Converting notebook Working_Prototype.ipynb to html\n",
      "[NbConvertApp] Writing 584068 bytes to Working_Prototype.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter-nbconvert --TemplateExporter.exclude_output=True --to html Working_Prototype.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1e9acf876183bd7ab24d8e78ca2cda958ecdc2a0fd8d5e11f3339a8535eddd1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
